{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controlling-jones",
   "metadata": {},
   "source": [
    "## Homework 4: Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-glasgow",
   "metadata": {},
   "source": [
    "In this homework you will get more practice in combining data from different sources and in fitting a linear regression model in order to understand the relationship betweem various properties of words and the speed with which people can recognize them.\n",
    "\n",
    "We will be using the files `ldt_trials.csv` and `word_properties.csv` in the `data` folder. These files contain lexical decision reaction times for each participant and each word (`ldt_trials.csv`) and information about various word properties such as word length, word frequency, concreteness and emotional valence (`word_properties.csv`). These data were obtained from the English Lexicon Project: https://elexicon.wustl.edu/index.html\n",
    "\n",
    "Your main goal for this homework is to understand how reaction times to recognize a word vary as a function of each of these word properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-entity",
   "metadata": {},
   "source": [
    "#### Part 1: Loading and organizing the data\n",
    "\n",
    "Since the reaction times and the word properties are stored in different files, you will have to load them separately, then combine them before analyzing the data. The `ldt_trials.csv` file is in tidy format and each row contains RTs in response to a particular word for a particular participants. The `word_properties.csv` file contains one row per word listing its various properties in columns.\n",
    "\n",
    "First, load the two datasets. Use the `str`, `heads` and `summary` commands for each dataset in order to understand how they are structured **(1 pt)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-transcript",
   "metadata": {},
   "source": [
    "We now want to merge the two datasets such that we have the properties of each word listed in every row of the `ldt_trial.csv`. Use the `left_join()` command from the `tidyverse` package to join the two datasets. You have to specify which column you are mergin by. In this case, the columns `Word` in the `word_properties` dataset and the column `D_word` in the `ldt_trials` dataset should be used for the merging (hint: read the documentation of the `left_join()` function to understand how the `by=c()` argument works). Join the two datasets by the respective columns and save the output in a new variable  **(2 pt)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incredible-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-meeting",
   "metadata": {},
   "source": [
    "You will notice that we do not have word characteristics for every word that the participants were tested (e.g., there are many NA values in the Length, Concreteness, etc, columns of the new merged dataset. Filter the new dataset and save it to a new variable so that the new dataset only has rows for which word characteristics are present (hint: you can use the `!is.na(column_name)` argument in the filter command to remove all rows in which `column_name` has NA values  **(1 pt)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incredible-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-campus",
   "metadata": {},
   "source": [
    "After these operations the final dataset should have 35978 rows. Use the `nrow()` command to confirm this. Use the `heads()` command to take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-pearl",
   "metadata": {},
   "source": [
    "The column `Sub_ID` contains the ID number for the different participants. How many participants are there in this experiment? (hint: you can combine the `unique()` and `length()` commands to answer this question)  **(1 pt)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-sperm",
   "metadata": {},
   "source": [
    "On average, how many observations are there for each participant? Calculate the mean and standard deviation of the number of observations per participant using the `group_by()` and `summarize()` commands  **(1 pt)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-glass",
   "metadata": {},
   "source": [
    "#### Part 2: Visualize and understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-communist",
   "metadata": {},
   "source": [
    "For each of the word properties (Length, SUBTLWF, Concreteness_Rating, Emotional_Valence), plot a scatterplot how the lexical decision reaction times (`D_RT`) changes. Fit a smooth line through the plot with the `geom_smooth()` command in the `ggplot` (hint: use the `stat_summary()` command of the ggplot call to summarise the y axis for each x axis point. hint2: for SUBTLWF, which is word frequency, first round the variable to remove the decimal point values -  e.g., `ggplot(newdf, aes(round(SUBTLWF), D_RT))`); for concretness and emotional valence, try plotting before and after rounding the x axis. For SUBTWLF, plot the data after transforming it to a logarithm  **(5 pt)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-wholesale",
   "metadata": {},
   "source": [
    "Based on the previous plots, for which of these predictions would a linear regression be a good model of reaction times? Why/why not  **(5 pt)**?\n",
    "\n",
    "> insert your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-basement",
   "metadata": {},
   "source": [
    "To what degree are the 4 predictors correlated with each other  **(2 pt)**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-external",
   "metadata": {},
   "source": [
    "## Part 3: Fit a linear model\n",
    "\n",
    "Use the `lm` command to fit a linear regression to the `D_RT` variable using the four predictors. Assign the output to a new variable called `ml1`. Use the `summary(ml1)` command to display the output of the model  **(2 pt)**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modified-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code ehre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-incidence",
   "metadata": {},
   "source": [
    "What is the intercept value and the slope for the word length predictor? Explain what these values means  **(3 pt)**:\n",
    "> insert response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-differential",
   "metadata": {},
   "source": [
    "What is the R-squared value? What does this mean?  **(3 pt)**\n",
    "> insert response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-roman",
   "metadata": {},
   "source": [
    "As you noticed, the R-squared value is really low. This is because there is a lot of individual differences in how fast people react. These differences cannot be explained by word characteristics. One way to account for individual differences is to summarize the data over participants, and obtain the average RTs for each word. Let's do this and refit the model.\n",
    "\n",
    "First, use the `group_by` and `summarise` commands to calculate the average RT for each word. In order to keep the word characteristics, include those columns in the `group_by` call. E.g.: `group_by(D_word, Length, SUBTLWF, Concreteness_Rating, Emotional_Valence)`. Save the result to a new variable. Use the `heads` command to look at the data  **(2 pt)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "objective-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-retro",
   "metadata": {},
   "source": [
    "Now, fit the linear model again using the summarised data. Do the estimates of intercept and slope differ much from the previous model? How about the R-squared value? If so, why do you think that is the case  **(3 pt)**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seasonal-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-comfort",
   "metadata": {},
   "source": [
    "> insert response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-cathedral",
   "metadata": {},
   "source": [
    "Finally, change the predictor for the SUBTLWF to be the log(SUBTLWF) value. Does the R-squared increase? Why/why not  **(2 pt)**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-burton",
   "metadata": {},
   "source": [
    "> insert response here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
